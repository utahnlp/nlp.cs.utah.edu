@article{gupta2022is-my-model,
  author = {Gupta, Vivek and Bhat, Riyaz A and Ghosal, Atreya and Shrivastava, Manish and Singh, Maneesh and Srikumar, Vivek},
  title = {{Is My Model Using The Right Evidence? Systematic Probes for Examining Evidence-Based Tabular Reasoning}},
  journal = {Transactions of the Association for Computational Linguistics},
  year = {2022},
  volume = {10},
  tags = {Probing representations and models,Textual entailment},
  paper = {pdfs/gupta2022is-my-model.pdf}
}

@inproceedings{gupta2022right-for,
  author = {Gupta, Vivek and Zhang, Shuo and Vempala, Alakananda and He, Yujie and Choji, Temma and Srikumar, Vivek},
  title = {{Right for the Right Reason: Evidence Extraction for Trustworthy Tabular Reasoning}},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year = {2022},
  tags = {Textual entailment,Probing representations and models},
  paper = {pdfs/gupta2022right-for.pdf}
}

@inproceedings{mehta2022psychotherapy,
  author = {Mehta, Maitrey and Caperton, Derek and Axford, Katherine and Weitzman, Lauren and Atkins, David and Srikumar, Vivek and Imel, Zac},
  title = {{Psychotherapy is Not One Thing: Simultaneous Modeling of Different Therapeutic Approaches}},
  booktitle = {Proceedings of the Eighth Workshop on Computational Linguistics and Clinical Psychology},
  year = {2022},
  tags = {Clinical Psychology & Technology},
  paper = {pdfs/mehta2022psychotherapy.pdf}
}

@inproceedings{zhou2022closer,
  author = {Zhou, Yichu and Srikumar, Vivek},
  title = {{A Closer Look at How Fine-tuning Changes BERT}},
  booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year = {2022},
  tags = {Probing representations and models,Representations & Learning},
  paper = {pdfs/zhou2022closer.pdf}
}

@inproceedings{liu2022putting,
    author = {Liu, Yang Janet  and Hwang, Jena D.  and Schneider, Nathan  and Srikumar, Vivek},
    title = {{Putting Context in SNACS: A 5-Way Classification of Adpositional Pragmatic Markers}},
    booktitle = {Proceedings of The 16th Lingusitic Annotation Workshop (LAW-XVI)},
    month = jun,
    pages = {120--128},
    year = {2022},
    keywords = {workshop},
    tags = {Semantics},
    paper = {pdfs/liu2022putting.pdf}
}

@article{palaskar2022advances,
  author    = {Shruti Palaskar and
               Akshita Bhagia and
               Yonatan Bisk and
               Florian Metze and
               Alan W. Black and
               Ana Marasovi\'{c}},
  title     = {On Advances in Text Generation from Images Beyond Captioning: {A}
               Case Study in Self-Rationalization},
  journal   = {CoRR},
  volume    = {abs/2205.11686},
  year      = {2022},
  url       = {https://doi.org/10.48550/arXiv.2205.11686},
  doi       = {10.48550/arXiv.2205.11686},
  eprinttype = {arXiv},
  eprint    = {2205.11686},
  timestamp = {Mon, 30 May 2022 15:47:29 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2205-11686.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  tags={Multimodality, Interpretability, Interactivity & Analysis of Models}
}

@article{hessel2022cartoons,
  author    = {Jack Hessel and Ana Marasovi\'{c} and Jena D. Hwang and Lillian Lee and Jeff Da and Rowan Zellers and Robert Mankoff and Yejin Choi},
  title     = {Do Androids Laugh at Electric Sheep? {H}umor "Understanding" Benchmarks from The New Yorker Caption Contest},
  journal   = {CoRR},
  volume    = {abs/2209.06293},
  year      = {2022},
  url       = {https://arxiv.org/abs/2209.06293},
  eprinttype = {arXiv},
  eprint    = {2209.06293},
  tags={Multimodality, Interpretability, Interactivity & Analysis of Models}
}

@inproceedings{marasovic-etal-2022-shot,
    title = "Few-Shot Self-Rationalization with Natural Language Prompts",
    author = "Marasovic, Ana  and
      Beltagy, Iz  and
      Downey, Doug  and
      Peters, Matthew",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2022",
    month = jul,
    year = "2022",
    address = "Seattle, United States",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-naacl.31",
    doi = "10.18653/v1/2022.findings-naacl.31",
    pages = "410--424",
    abstract = "Self-rationalization models that predict task labels and generate free-text elaborations for their predictions could enable more intuitive interaction with NLP systems. These models are, however, currently trained with a large amount of human-written free-text explanations for each task which hinders their broader usage. We propose to study a more realistic setting of self-rationalization using few training examples. We present FEB{---}a standardized collection of four existing English-language datasets and associated metrics. We identify the right prompting approach by extensively exploring natural language prompts on FEB. Then, by using this prompt and scaling the model size, we demonstrate that making progress on few-shot self-rationalization is possible. We show there is still ample room for improvement in this task: the average plausibility of generated explanations assessed by human annotators is at most 51{\%} (with GPT-3), while plausibility of human explanations is 76{\%}. We hope that FEB and our proposed approach will spur the community to take on the few-shot self-rationalization challenge.",
}